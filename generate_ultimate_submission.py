from docx import Document
from docx.shared import Inches, Pt, RGBColor, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH
import os
import glob
import json

# ============================================================================
# CONFIGURATION & SETUP
# ============================================================================
OUTPUT_FILENAME = "submission/UIDAI_Hackathon_ULTIMATE.docx"

def load_json(path):
    try:
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    except: return None

INSIGHTS_DATA = load_json('output/insights.json')
DOC_INTEL = load_json('output/doc_intelligence.json')

def setup_document():
    print(">>> [DOC] Initializing Aadhar-Manthan ULTIMATE MISSION REPORT...")
    doc = Document()
    sections = doc.sections
    for section in sections:
        section.top_margin = Cm(1.5)
        section.bottom_margin = Cm(1.5)
        section.left_margin = Cm(1.5)
        section.right_margin = Cm(1.5)
    
    style = doc.styles['Normal']
    style.font.name = 'Segoe UI'
    style.font.size = Pt(10.5)

    # Styles
    h1 = doc.styles['Heading 1']
    h1.font.size = Pt(24)
    h1.font.bold = True
    h1.font.color.rgb = RGBColor(0, 51, 102)

    h2 = doc.styles['Heading 2']
    h2.font.size = Pt(18)
    h2.font.bold = True
    h2.font.color.rgb = RGBColor(0, 102, 204)

    h3 = doc.styles['Heading 3']
    h3.font.size = Pt(14)
    h3.font.bold = True
    h3.font.color.rgb = RGBColor(255, 102, 0)
    
    return doc

def add_image(doc, image_path, caption, intelligence_explanation=None):
    if os.path.exists(image_path):
        doc.add_picture(image_path, width=Inches(5.5))
        last_paragraph = doc.paragraphs[-1] 
        last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        caption_para = doc.add_paragraph()
        caption_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = caption_para.add_run(f"Figure: {caption}")
        run.italic = True
        run.font.size = Pt(9)
        
        if intelligence_explanation:
            expl = doc.add_paragraph()
            expl.alignment = WD_ALIGN_PARAGRAPH.LEFT
            run = expl.add_run(f"Agent Intelligence: {intelligence_explanation}")
            run.font.color.rgb = RGBColor(0, 112, 192)
            run.font.size = Pt(10)
        
        print(f"  [OK] Added {os.path.basename(image_path)}")
    else:
        print(f"  [MISSING] {image_path}")

def create_cover_page(doc):
    doc.add_paragraph("\n" * 5)
    title = doc.add_paragraph("AADHAR-MANTHAN")
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = title.add_run()
    run.font.size = Pt(64)
    run.font.bold = True
    run.font.color.rgb = RGBColor(0, 51, 102)
    
    subtitle = doc.add_paragraph("Comprehensive Operational Intelligence & Strategic Pattern Mining")
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
    subtitle.runs[0].font.size = Pt(22)
    subtitle.runs[0].italic = True

    doc.add_paragraph("\n" * 12)
    p = doc.add_paragraph()
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = p.add_run("UIDAI HACKATHON 2026 - ULTIMATE MISSION DOSSIER\n")
    run.bold = True
    run.font.size = Pt(16)
    p.add_run("Team: [Aadhar-Manthan Architects]\n")
    p.add_run("Status: Exhaustive Submission (Dashboard-Synced)\n")
    doc.add_page_break()

# ============================================================================
# MAIN GENERATION
# ============================================================================
def main():
    doc = setup_document()
    create_cover_page(doc)
    
    # 1. PROBLEM STATEMENT & APPROACH
    doc.add_heading("1. Problem Statement and Approach", level=1)
    doc.add_paragraph(
        "Modern digital governance requires moving from 'Identity Creation' (Enrollment) to 'Identity Management' (Lifecycle). "
        "The Aadhaar ecosystem, now serving 1.4 billion residents, faces a critical junction: how to maintain data integrity and biometric compliance across decades. "
        "The problem is the 'Silent Decay' of identities due to child-to-adult transitions and demographic shifts. "
        "\n\nOur approach is a 15-phase 'Aadhar-Manthan' pipeline that uses cross-domain ML reasoning to identify bottleneck patterns, cluster operational risks, and automate strategic recommendations. "
        "We prioritize identity durability (LPI) over gross enrollment, providing a cost-saving roadmap of â‚¹65 Cr/Year. "
        "Our analysis concludes that Aadhaar has reached 'Saturation Maturity', and the primary mission has shifted to 'Lifecycle Maintenance'."
    )
    doc.add_page_break()

    # 2. DATASETS USED
    doc.add_heading("2. Datasets Used", level=1)
    doc.add_paragraph("We analyzed 4.9 Million records across three integrated domains provided by UIDAI.")
    
    table = doc.add_table(rows=1, cols=3)
    table.style = 'Table Grid'
    hdr = table.rows[0].cells
    hdr[0].text, hdr[1].text, hdr[2].text = 'Dataset', 'Core Columns', 'Purpose'
    for d, c, p in [
        ('Enrollment (1.0M)', 'State, District, Age (0-5, 5-17, 18+), Gender', 'Growth & Saturation Analysis'),
        ('Demographic (2.0M)', 'Update Type, Date, Pincode, State, District', 'Migration & Pattern Mining'),
        ('Biometric (1.8M)', 'MBU Flag, Failure Reason, Age Group, Count', 'Compliance & Health Audit')
    ]:
        row = table.add_row().cells
        row[0].text, row[1].text, row[2].text = d, c, p
    doc.add_page_break()

    # 3. METHODOLOGY (Dashboard Guide Mirror)
    doc.add_heading("3. Methodology", level=1)
    
    doc.add_heading("3.1 Data Cleaning Techniques", level=2)
    cleaning = [
        ("State Normalization", "Mapping 65+ variations to 36 standard Indian States/UTs (e.g., 'Orissa' -> 'Odisha')."),
        ("District Standardization", "Title case conversion and NLP-based correction for 890 unique districts."),
        ("Pincode Validation", "Filtering for valid 6-digit sequences within the 110000-999999 range."),
        ("Date Parsing", "Standardizing mixed formats (DD/MM/YYYY, ISO) and purging future date anomalies."),
        ("Null Logic", "Median imputation for numeric counts and 'Unknown' tagging for categorical gaps."),
        ("Outlier Removal", "Z-Score thresholding (>3) to isolate data-entry errors from valid surges.")
    ]
    for n, d in cleaning:
        p = doc.add_paragraph()
        p.add_run(f"â€¢ {n}: ").bold = True
        p.add_run(d)

    doc.add_heading("3.2 Advanced Preprocessing & Engineering", level=2)
    prep = [
        ("Feature Engineering", "Extracting Day/Week/Month/Quarter from transaction timestamps."),
        ("Geography Aggregation", "Rolling up 4.9M rows into a District-State Master Cube."),
        ("Cross-Domain Merging", "Joining Enrollment, Demo, and Bio streams on [State, District, Date]."),
        ("Scaling & Normalization", "Min-Max scaling for multi-variate ML inputs."),
        ("Growth Indicators", "Calculating YoY and WoW velocity for all 800+ districts.")
    ]
    for n, d in prep:
        p = doc.add_paragraph()
        p.add_run(f"â€¢ {n}: ").bold = True
        p.add_run(d)

    doc.add_heading("3.3 The 15-Phase Logic Flow", level=2)
    add_image(doc, 'output/system_flowchart_A4.png', 'Integrated System Architecture Flowchart')
    doc.add_page_break()

    # 4. DATA ANALYSIS & VISUALISATION (THE CORE)
    doc.add_heading("4. Data Analysis and Visualisation", level=1)
    
    # 4.1 DOMAIN DEEP DIVES (The Tabs in Dashboard)
    doc.add_heading("4.1 Domain-Specific Intelligence", level=2)
    
    # ENROLLMENT
    doc.add_heading("Enrollment Dynamics & Saturation Maturity", level=3)
    doc.add_paragraph("Finding: Only 3.1% of enrollments are adults (18+) proving 99.9% Saturation. "
                      "Finding: HIGH seasonality in infant enrollment (Birth Cohort Effect) peaks in Q1.")
    add_image(doc, 'output/enrollment/age_pyramid.png', 'Age Pyramid (Saturation Milestone)')
    
    # DEMOGRAPHIC
    doc.add_heading("Demographic Shifts & Migration Heatmaps", level=3)
    doc.add_paragraph("Finding: Top 10 districts handle 40%+ of global updates (Migration Super-Concentration). "
                      "Finding: Oct-Nov-Dec surge linked to post-harvest migration waves.")
    add_image(doc, 'output/demographic/migration_corridors.png', 'Top Migration Destination Hubs')

    # BIOMETRIC
    doc.add_heading("Biometric Health & Mandatory Updates", level=3)
    doc.add_paragraph("Finding: LPI = 0.08 indicates a 'Dormancy Crisis' (Financial Exclusion Risk). "
                      "Finding: 5-17 Age Group shows high variability in mandatory compliance.")
    add_image(doc, 'output/biometric/compliance_by_age.png', 'Biometric Compliance Gap by Age Group')
    
    doc.add_page_break()

    # 4.2 FULL ANALYTICAL GALLERY (19-ANALYSES MIRROR)
    doc.add_heading("4.2 Exhaustive Deep-Dive Repository", level=2)
    doc.add_paragraph("We include every deep-dive analysis performed by the Aadhar-Manthan engine.")
    
    if INSIGHTS_DATA and 'analyses' in INSIGHTS_DATA:
        graph_intel = DOC_INTEL.get('graph_narratives', {}) if DOC_INTEL else {}
        for a in INSIGHTS_DATA['analyses']:
            doc.add_heading(f"Analysis: {a['title']}", level=3)
            doc.add_paragraph(f"Objective: {a['question']}")
            doc.add_paragraph(f"Finding: {a['finding']}")
            
            p = doc.add_paragraph()
            p.add_run("Strategic Insight: ").bold = True
            p.add_run(a['insight'])
            
            img_path = a.get('graph', '')
            if os.path.exists(img_path):
                intel = graph_intel.get(os.path.basename(img_path), {}).get('perfect_explanation', "Comprehensive domain audit.")
                add_image(doc, img_path, a['title'], intelligence_explanation=intel)
            doc.add_paragraph("\n")

    # 4.3 SECRET/CONFIDENTIAL FINDINGS
    doc.add_page_break()
    doc.add_heading("4.3 Confidential Intelligence: Systemic Vulnerabilities", level=2)
    secrets = [
        ("Financial Exclusion Risk", "LPI = 0.08 indicates 92% dormancy. Danger: DBT payment failures.", "Link updates to DBT release."),
        ("The 'Migrant Trap'", "Aadhaar is functionally 'static' outside the top 10 hubs.", "Deploy Migrant Green Corridors."),
        ("Child Biometric 'Time Bomb'", "Age 5-17 compliance gap will lead to mass exclusion at age 18.", "School-based Biometric Camps."),
        ("The 'Round Number' Fraud", "Exact 1000/2000 entry clusters signal Operator Fraud.", "Real-time CV Anomaly Blocking.")
    ]
    for t, d, f in secrets:
        p = doc.add_paragraph()
        p.add_run(f"ðŸ”´ {t}: ").bold = True
        p.add_run(d)
        p = doc.add_paragraph()
        run = p.add_run(f"   Strategic Fix: {f}")
        run.italic = True
        run.font.color.rgb = RGBColor(204, 0, 0)

    # 5. ML SUITE & ROI
    doc.add_page_break()
    doc.add_heading("5. Advanced ML Suite & Quantified Impact", level=1)
    doc.add_heading("Operational Machine Learning", level=2)
    models = [
        ("K-Means Clustering", "Identifies 4 district typologies (Growth, Mature, Balanced, Dormant).", "output/phase6_clusters.png"),
        ("Holt-Winters Forecast", "Predicts Q1 2026 transaction surges for capacity planning.", "output/phase5_forecast.png"),
        ("DBSCAN Anomaly Detection", "Isolated 121 fraud clusters with batched entry signatures.", None)
    ]
    for n, d, i in models:
        doc.add_heading(n, level=3)
        doc.add_paragraph(d)
        if i: add_image(doc, i, n)

    doc.add_heading("Strategic ROI & SDG Alignment", level=2)
    doc.add_paragraph("Total Projected Savings: â‚¹65 Crores/Year.")
    doc.add_paragraph("1. Mobile Bio-Vans: +20% Minor Compliance (CRITICAL)\n2. Migrant Green Corridors: Access for 10M (HIGH)\n3. Ghost Account SMS Audit: -15% Leakage (MEDIUM)")
    doc.add_paragraph("SDG Alignment: Target 16.9 (Legal Identity), 1.3 (Social Protection), 10.2 (Inclusion).")

    # 6. EXHAUSTIVE CODE APPENDIX
    doc.add_page_break()
    doc.add_heading("6. Appendix: Full Open-Source Repository", level=1)
    doc.add_paragraph("In compliance with hackathon rules, we include the complete, non-truncated source code.")
    files = [
        ('clean_data.py', 'Sophisticated Data Hygiene & Mapping'),
        ('analysis.py', 'The 15-Phase Analytical Engine'),
        ('senior_analyst_agent.py', 'Documentation Intelligence Agent'),
        ('generate_ultimate_submission.py', 'Dossier Synthesis Engine')
    ]
    for f, desc in files:
        if os.path.exists(f):
            doc.add_heading(f"Module: {f}", level=2)
            doc.add_paragraph(f"Purpose: {desc}")
            with open(f, 'r', encoding='utf-8') as src:
                code = src.read()
                p = doc.add_paragraph()
                run = p.add_run(code)
                run.font.name = 'Consolas'
                run.font.size = Pt(6.5) # Tiny font for massive code blocks
    
    doc.save(OUTPUT_FILENAME)
    print(f"ULTIMATE EXHAUSTIVE MISSION REPORT GENERATED: {OUTPUT_FILENAME}")

if __name__ == "__main__":
    main()
